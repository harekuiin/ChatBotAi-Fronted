# ğŸ“‹ Instrucciones de Uso - Microservicio OpenAI

## ğŸ¯ PropÃ³sito

Este microservicio es una versiÃ³n independiente y portable del backend, lista para:
- IntegraciÃ³n con cualquier frontend
- ConexiÃ³n con otros microservicios
- Despliegue independiente
- ReutilizaciÃ³n en otros proyectos

## âš¡ Inicio RÃ¡pido

### 1. Instalar Dependencias
```bash
cd Microservicio_Openai
pip install -r requirements.txt
```

### 2. Configurar Variables de Entorno
```bash
# Copiar archivo de ejemplo
copy env.example .env

# Editar .env y agregar tu API key
OPENAI_API_KEY=tu-clave-openai-aqui
```

### 3. Ejecutar el Microservicio
```bash
python run.py
```

El servidor estarÃ¡ en: **http://localhost:8000**

## ğŸ”Œ IntegraciÃ³n con Frontend

### Ejemplo JavaScript/TypeScript

```javascript
const API_URL = 'http://localhost:8000';

// Chat con streaming
async function chatStream(question, conversationId) {
    const response = await fetch(`${API_URL}/coach/stream`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            question: question,
            conversation_id: conversationId || `user-${Date.now()}`
        })
    });
    
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    
    while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value);
        // Procesar chunk...
    }
}

// Plan de coaching
async function getCoachPlan(userProfile, riskScore, topDrivers) {
    const response = await fetch(`${API_URL}/coach`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            user_profile: userProfile,
            risk_score: riskScore,
            top_drivers: topDrivers
        })
    });
    
    return await response.json();
}
```

## ğŸ”— IntegraciÃ³n con Otros Microservicios

### Ejemplo Python

```python
import requests

MICROSERVICE_URL = "http://localhost:8000"

# Llamar al microservicio desde otro servicio
def get_chat_response(question, conversation_id=None):
    response = requests.post(
        f"{MICROSERVICE_URL}/coach/stream",
        json={
            "question": question,
            "conversation_id": conversation_id
        },
        stream=True
    )
    return response

# Obtener plan de coaching
def get_coach_plan(user_profile, risk_score, top_drivers):
    response = requests.post(
        f"{MICROSERVICE_URL}/coach",
        json={
            "user_profile": user_profile,
            "risk_score": risk_score,
            "top_drivers": top_drivers
        }
    )
    return response.json()
```

### Ejemplo Node.js

```javascript
const axios = require('axios');

const MICROSERVICE_URL = 'http://localhost:8000';

// Chat con streaming
async function chatStream(question, conversationId) {
    const response = await axios.post(
        `${MICROSERVICE_URL}/coach/stream`,
        {
            question: question,
            conversation_id: conversationId
        },
        { responseType: 'stream' }
    );
    
    return response.data;
}

// Plan de coaching
async function getCoachPlan(userProfile, riskScore, topDrivers) {
    const response = await axios.post(`${MICROSERVICE_URL}/coach`, {
        user_profile: userProfile,
        risk_score: riskScore,
        top_drivers: topDrivers
    });
    
    return response.data;
}
```

## ğŸ“ Estructura de Archivos

```
Microservicio_Openai/
â”œâ”€â”€ app/                      # CÃ³digo fuente del microservicio
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # Endpoints FastAPI
â”‚   â”œâ”€â”€ config.py            # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ models.py            # Modelos de datos
â”‚   â”œâ”€â”€ rag_service.py       # Servicio RAG
â”‚   â”œâ”€â”€ chat_service.py      # Servicio de chat
â”‚   â”œâ”€â”€ document_processor.py # Procesador de documentos
â”‚   â””â”€â”€ guardrails.py        # Guardrails mÃ©dicos
â”œâ”€â”€ kb/                      # Documentos de conocimiento (crear manualmente)
â”œâ”€â”€ requirements.txt         # Dependencias Python
â”œâ”€â”€ run.py                   # Script de inicio
â”œâ”€â”€ env.example              # Ejemplo de configuraciÃ³n
â”œâ”€â”€ README.md                # DocumentaciÃ³n principal
â”œâ”€â”€ INSTRUCCIONES.md         # Este archivo
â””â”€â”€ .gitignore               # Archivos a ignorar en Git
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar Puerto

Edita `.env`:
```env
SERVICE_PORT=8080  # Cambiar puerto
```

### Cambiar Modelo de OpenAI

Edita `.env`:
```env
OPENAI_MODEL=gpt-4  # Usar GPT-4 en lugar de GPT-3.5
```

### Desactivar Guardrails

Edita `.env`:
```env
ENABLE_MEDICAL_GUARDRAILS=false
```

## ğŸ“ Cargar Documentos

1. Coloca tus documentos en la carpeta `kb/`
2. Soporta formatos: `.txt`, `.svg`
3. Recarga documentos:
   ```bash
   # VÃ­a API
   POST http://localhost:8000/documents/reload
   
   # O sube nuevos documentos
   POST http://localhost:8000/documents/upload
   ```

## ğŸš€ Despliegue

### Desarrollo Local
```bash
python run.py
```

### ProducciÃ³n (con Uvicorn)
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### Docker (futuro)
```dockerfile
# Dockerfile puede agregarse despuÃ©s
FROM python:3.11
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "run.py"]
```

## ğŸ” VerificaciÃ³n

### Health Check
```bash
curl http://localhost:8000/health
```

### DocumentaciÃ³n Interactiva
- Swagger: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## âš ï¸ Notas Importantes

1. **API Key**: Es obligatoria para que funcione
2. **CORS**: EstÃ¡ configurado para aceptar cualquier origen (cambiar en producciÃ³n)
3. **Memoria**: Se mantiene por `conversation_id`, se pierde al reiniciar
4. **Vector Store**: Se crea automÃ¡ticamente en `chroma_db/`
5. **Documentos**: ColÃ³calos en `kb/` antes de iniciar

## ğŸ†˜ Troubleshooting

### Error: "No module named 'app'"
- AsegÃºrate de estar en el directorio `Microservicio_Openai`
- Verifica que `app/__init__.py` existe

### Error: "OPENAI_API_KEY not found"
- Crea el archivo `.env` desde `env.example`
- Agrega tu API key de OpenAI

### Error: "Service not ready"
- Espera unos segundos despuÃ©s de iniciar
- Verifica que los documentos estÃ©n en `kb/`

---

**Listo para integrar! ğŸš€**


