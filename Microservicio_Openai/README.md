# Microservicio OpenAI - RAG Chat API

Microservicio independiente para integraciÃ³n con frontends y otros microservicios.

## ğŸš€ CaracterÃ­sticas

- API REST con FastAPI
- Sistema RAG (Retrieval-Augmented Generation)
- Chat con memoria conversacional
- Streaming de respuestas en tiempo real
- Soporte para documentos TXT y SVG
- Guardrails mÃ©dicos configurables
- CORS configurado para integraciÃ³n

## ğŸ“‹ InstalaciÃ³n RÃ¡pida

1. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

2. **Configurar variables de entorno:**
```bash
# Copiar el archivo de ejemplo
copy env.example .env

# Editar .env y agregar tu OPENAI_API_KEY
OPENAI_API_KEY=tu-clave-aqui
```

3. **Ejecutar el microservicio:**
```bash
python run.py
```

El servidor estarÃ¡ disponible en: `http://localhost:8000`

## ğŸ”Œ Endpoints Principales

- `GET /` - Health check bÃ¡sico
- `GET /health` - Estado detallado de servicios
- `POST /chat` - Chat bÃ¡sico (sin memoria)
- `POST /coach` - Plan de coaching personalizado
- `POST /coach/stream` - Chat con streaming y memoria
- `GET /documents/list` - Listar documentos
- `POST /documents/upload` - Subir documentos
- `POST /documents/reload` - Recargar documentos

## ğŸ“š DocumentaciÃ³n Interactiva

Una vez ejecutando, accede a:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## ğŸ”§ ConfiguraciÃ³n

Edita el archivo `.env` para configurar:

- `OPENAI_API_KEY` - **OBLIGATORIO** - Tu clave de API de OpenAI
- `OPENAI_MODEL` - Modelo de chat (default: gpt-3.5-turbo-0125)
- `KB_DIRECTORY` - Directorio de documentos (default: ./kb)
- `SERVICE_PORT` - Puerto del servidor (default: 8000)
- `ENABLE_MEDICAL_GUARDRAILS` - Activar guardrails (default: true)

## ğŸ“ Estructura

```
Microservicio_Openai/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # Endpoints FastAPI
â”‚   â”œâ”€â”€ config.py            # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ models.py            # Modelos de datos
â”‚   â”œâ”€â”€ rag_service.py       # Servicio RAG bÃ¡sico
â”‚   â”œâ”€â”€ chat_service.py      # Servicio de chat avanzado
â”‚   â”œâ”€â”€ document_processor.py # Procesador de documentos
â”‚   â””â”€â”€ guardrails.py        # Guardrails mÃ©dicos
â”œâ”€â”€ kb/                      # Directorio de documentos (se crea automÃ¡ticamente)
â”œâ”€â”€ requirements.txt         # Dependencias
â”œâ”€â”€ run.py                   # Script de inicio
â”œâ”€â”€ env.example              # Ejemplo de configuraciÃ³n
â””â”€â”€ README.md               # Este archivo
```

## ğŸ”— IntegraciÃ³n con Frontend

El microservicio tiene CORS configurado para aceptar conexiones desde cualquier origen. Para integrarlo:

```javascript
const API_URL = 'http://localhost:8000';

// Ejemplo: Chat con streaming
fetch(`${API_URL}/coach/stream`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
        question: "Tu pregunta aquÃ­",
        conversation_id: "user-123"
    })
});
```

## ğŸ”— IntegraciÃ³n con Otros Microservicios

El microservicio puede ser llamado desde otros servicios mediante HTTP:

```python
import requests

response = requests.post(
    'http://localhost:8000/coach',
    json={
        "user_profile": {...},
        "risk_score": 0.65,
        "top_drivers": ["bmi", "waist"]
    }
)
```

## ğŸ“ Notas

- Los documentos se cargan desde el directorio `kb/`
- El vector store se crea automÃ¡ticamente en `chroma_db/`
- La memoria conversacional se mantiene por `conversation_id`
- Los guardrails mÃ©dicos son configurables vÃ­a `.env`

## ğŸ› ï¸ TecnologÃ­as

- FastAPI
- LangChain
- OpenAI
- ChromaDB
- Pydantic

---

**VersiÃ³n:** 1.0.0  
**Autor:** Hackathon Salud NHANES 2025


